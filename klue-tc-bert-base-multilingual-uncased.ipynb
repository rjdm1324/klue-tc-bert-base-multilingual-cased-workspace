{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805cae30",
   "metadata": {},
   "source": [
    "News Topic Classifier \n",
    "===\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203c7ee5",
   "metadata": {},
   "source": [
    "# 뉴스 헤드라인을 입력받아 Topic을 분류하는 모델\n",
    "```\n",
    "* Bert-base-multilingual-cased 모델을 klue-tc 데이터 셋으로 fine-tuning 하였습니다.\n",
    "* 코드는 huggingface 의 Fine-tuning a pretrained model 문서를 참조하였습니다.\n",
    "* workspace 는 Ainize의 workspace를 사용하였습니다.\n",
    "* Demo버전은 Ainize에서 확인 가능합니다.\n",
    "```\n",
    "-------\n",
    "##### 사전학습 모델 : [bert-base-multilingual-cased](https://huggingface.co/bert-base-multilingual-cased)\n",
    "##### 데이터 셋 : [klue-tc (a.k.a. YNAT) ](https://klue-benchmark.com/tasks/66/overview/description)\n",
    "##### 코드 참조 : [huggingface](https://huggingface.co/transformers/training.html)\n",
    "##### workspace : [Ainize](https://ainize.ai/workspace)\n",
    "##### endpoint : [Ainize](https://main-klue-tc-bert-base-multilingual-cased-rjdm1324.endpoint.ainize.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b7ddd4",
   "metadata": {},
   "source": [
    "------\n",
    "### 필요한 라이브러리를 install 하고 import 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184b7a5e",
   "metadata": {},
   "source": [
    "* Dataset : dataset을 trainer에 맞는 형식으로 만들기 위해 사용합니다.\n",
    "* TrainingArguments, Trainer : 모델 fine-tuning을 위해 사용합니다.\n",
    "* BertTokenizer, BertForSequenceClassification : huggingface에서 사전학습된 tokenizer와 model을 사용하기 위해 사용합니다.\n",
    "* LabelEncoder : label을 dataset에 맞는 형식으로 만들기 위해 사용합니다.\n",
    "* accuracy_score : 모델 정확도 측정을 위해 사용합니다.\n",
    "* cuda : GPU 사용을 위해 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a46bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.8.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (1.9.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.7.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (0.24.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2021.6.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.0.12)\n",
      "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.60.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.7.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.4.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers datasets scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4db4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import  TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch import cuda\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f665a3",
   "metadata": {},
   "source": [
    "### GPU는 [AI NETWORK workspace]()에서 제공하는 GPU를 사용하였습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa67f70",
   "metadata": {},
   "source": [
    "* gpu를 사용하기 위해 device를 cuda로 선언합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a260f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237497b",
   "metadata": {},
   "source": [
    "### json 형식의 데이터를 불러와 csv형식으로 바꾸어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bca33df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "with open('ynat-v1_train.json','r', encoding='utf-8') as f :\n",
    "    data = json.loads(f.read())\n",
    "df = pd.json_normalize(data)\n",
    "df.to_csv('ynat-v1_train.csv', index=False, encoding='utf-8')\n",
    "\n",
    "with open('ynat-v1_dev.json','r', encoding='utf-8') as f :\n",
    "    data = json.loads(f.read())\n",
    "df = pd.json_normalize(data)\n",
    "df.to_csv('ynat-v1_dev.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf76f00",
   "metadata": {},
   "source": [
    "### csv 파일을 불러와 title 과 label column을 추출합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961c4f76",
   "metadata": {},
   "source": [
    "* data는 train dataset의 title과 label column을 사용합니다.\n",
    "* data_dev dev dataset의 title과 label column을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d2e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ynat-v1_train.csv\")\n",
    "data_dev = pd.read_csv(\"ynat-v1_dev.csv\")\n",
    "data = data[['title','label']]\n",
    "data_dev = data_dev[['title','label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8ac9c",
   "metadata": {},
   "source": [
    "### tokenizer를 선언합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e196a7ed",
   "metadata": {},
   "source": [
    "* tokenizer는 사전 훈련된 bert-base-multilingual-cased tokenizer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f77fc03e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /workspace/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /workspace/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /workspace/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n",
      "tokenizer config file saved in ./tokenizer_config.json\n",
      "Special tokens file saved in ./special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',do_lower_case=False).save_pretrained(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9709e623",
   "metadata": {},
   "source": [
    "### label column을 형식에 맞게 encoding 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7637c",
   "metadata": {},
   "source": [
    "* data와 data_dev의 label column을 Dataset Class에서 사용할 수 있게 encoding합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98c3ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data[\"label\"] = label_encoder.fit_transform(data[\"label\"])\n",
    "data_dev[\"label\"] = label_encoder.fit_transform(data_dev[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296f697",
   "metadata": {},
   "source": [
    "### label을 분류할 class들과 mapping합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c347b38",
   "metadata": {},
   "source": [
    "* 출력을 위해 mapping에 label의 name을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0d5a5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'IT과학', 1: '경제', 2: '사회', 3: '생활문화', 4: '세계', 5: '스포츠', 6: '정치'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4422f1c3",
   "metadata": {},
   "source": [
    "### 학습에 필요한 파라미터를 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27151e6",
   "metadata": {},
   "source": [
    "* label의 개수가 7개 이므로 num_labels를 7로 설정합니다.\n",
    "* 나머지 파라미터를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8afa6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels=7\n",
    "max_len = 128\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "log_interval = 200\n",
    "learning_rate =  5e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263eac52",
   "metadata": {},
   "source": [
    "### train을 위한 data와 evalutaion을 위한 data를 나누고 tokenizing을 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c840f6",
   "metadata": {},
   "source": [
    "* 각 dataset을 tokenizing을 하여 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1dac44dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train= list(data['title'])\n",
    "y_train= list(data['label'])\n",
    "X_val = list(data_dev['title'])\n",
    "y_val = list(data_dev['label'])\n",
    "X_train_tokenized = tokenizer(X_train, padding=True, truncation = True, max_length =max_len)\n",
    "X_val_tokenized = tokenizer(X_val, padding=True, truncation = True, max_length =max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10567966",
   "metadata": {},
   "source": [
    "### tokenizing된 title과 label을 data set으로 만드는 class를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3960ab17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09580cab",
   "metadata": {},
   "source": [
    "### train data set과 evaluation data set으로 나누어줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b1c586",
   "metadata": {},
   "source": [
    "* train_dataset은 train을 할 때 사용합니다.\n",
    "* val_dataset은 evaluation할 때 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a177df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(X_train_tokenized, y_train)\n",
    "val_dataset = Dataset(X_val_tokenized, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b45a0c",
   "metadata": {},
   "source": [
    "### model을 선언합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09b279c",
   "metadata": {},
   "source": [
    "* huggingface에서 사전 학습된 bert-base-multilingual-cased 모델을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "badc07ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',num_labels=num_labels).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21eea2e",
   "metadata": {},
   "source": [
    "### accuracy를 측정하는 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65569007",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa30724",
   "metadata": {},
   "source": [
    "### training arguments를 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13ca60",
   "metadata": {},
   "source": [
    "* TrainingArguments를 통해 args에 arguments를 정의하고 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a10f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    learning_rate =  learning_rate ,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_steps= log_interval ,\n",
    "    output_dir=\"output\",\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='log',\n",
    "    load_best_model_at_end=True,\n",
    "    evaluation_strategy=\"steps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c289de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2db02",
   "metadata": {},
   "source": [
    "### trainer를 설정하고 학습을 시작합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46fb0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27c7394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 45678\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3570\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3570' max='3570' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3570/3570 24:28, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.298600</td>\n",
       "      <td>0.881617</td>\n",
       "      <td>0.693972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.636000</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.673877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.553000</td>\n",
       "      <td>0.836179</td>\n",
       "      <td>0.700999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.481800</td>\n",
       "      <td>0.803289</td>\n",
       "      <td>0.721423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.436500</td>\n",
       "      <td>0.568277</td>\n",
       "      <td>0.799165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.574548</td>\n",
       "      <td>0.802020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.584228</td>\n",
       "      <td>0.801581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.318400</td>\n",
       "      <td>0.601114</td>\n",
       "      <td>0.796640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.587800</td>\n",
       "      <td>0.800044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.301900</td>\n",
       "      <td>0.493249</td>\n",
       "      <td>0.827825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.517956</td>\n",
       "      <td>0.833535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.220200</td>\n",
       "      <td>0.571455</td>\n",
       "      <td>0.814319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.575481</td>\n",
       "      <td>0.818052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.210200</td>\n",
       "      <td>0.554330</td>\n",
       "      <td>0.816405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.592056</td>\n",
       "      <td>0.828703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.572350</td>\n",
       "      <td>0.830350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.596716</td>\n",
       "      <td>0.826946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-200\n",
      "Configuration saved in output/checkpoint-200/config.json\n",
      "Model weights saved in output/checkpoint-200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-400\n",
      "Configuration saved in output/checkpoint-400/config.json\n",
      "Model weights saved in output/checkpoint-400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-600\n",
      "Configuration saved in output/checkpoint-600/config.json\n",
      "Model weights saved in output/checkpoint-600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-800\n",
      "Configuration saved in output/checkpoint-800/config.json\n",
      "Model weights saved in output/checkpoint-800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-1000\n",
      "Configuration saved in output/checkpoint-1000/config.json\n",
      "Model weights saved in output/checkpoint-1000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-1200\n",
      "Configuration saved in output/checkpoint-1200/config.json\n",
      "Model weights saved in output/checkpoint-1200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-1600\n",
      "Configuration saved in output/checkpoint-1600/config.json\n",
      "Model weights saved in output/checkpoint-1600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-1800\n",
      "Configuration saved in output/checkpoint-1800/config.json\n",
      "Model weights saved in output/checkpoint-1800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-2000\n",
      "Configuration saved in output/checkpoint-2000/config.json\n",
      "Model weights saved in output/checkpoint-2000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-2200\n",
      "Configuration saved in output/checkpoint-2200/config.json\n",
      "Model weights saved in output/checkpoint-2200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-2400\n",
      "Configuration saved in output/checkpoint-2400/config.json\n",
      "Model weights saved in output/checkpoint-2400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-2600\n",
      "Configuration saved in output/checkpoint-2600/config.json\n",
      "Model weights saved in output/checkpoint-2600/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-2800\n",
      "Configuration saved in output/checkpoint-2800/config.json\n",
      "Model weights saved in output/checkpoint-2800/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-3000\n",
      "Configuration saved in output/checkpoint-3000/config.json\n",
      "Model weights saved in output/checkpoint-3000/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-3200\n",
      "Configuration saved in output/checkpoint-3200/config.json\n",
      "Model weights saved in output/checkpoint-3200/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to output/checkpoint-3400\n",
      "Configuration saved in output/checkpoint-3400/config.json\n",
      "Model weights saved in output/checkpoint-3400/pytorch_model.bin\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from output/checkpoint-2000 (score: 0.4932490885257721).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3570, training_loss=0.3722160959110207, metrics={'train_runtime': 1477.3876, 'train_samples_per_second': 154.59, 'train_steps_per_second': 2.416, 'total_flos': 9017901201863340.0, 'train_loss': 0.3722160959110207, 'epoch': 5.0})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f960f9b",
   "metadata": {},
   "source": [
    "### 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e20aa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 9107\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='143' max='143' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [143/143 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4932490885257721,\n",
       " 'eval_accuracy': 0.8278247501921598,\n",
       " 'eval_runtime': 16.777,\n",
       " 'eval_samples_per_second': 542.825,\n",
       " 'eval_steps_per_second': 8.524,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a68a40b",
   "metadata": {},
   "source": [
    "### 모델을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dc87c13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in klue-ynat-bert-base-multilingual-cased/config.json\n",
      "Model weights saved in klue-ynat-bert-base-multilingual-cased/pytorch_model.bin\n",
      "tokenizer config file saved in klue-ynat-bert-base-multilingual-cased/tokenizer_config.json\n",
      "Special tokens file saved in klue-ynat-bert-base-multilingual-cased/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('klue-ynat-bert-base-multilingual-cased/tokenizer_config.json',\n",
       " 'klue-ynat-bert-base-multilingual-cased/special_tokens_map.json',\n",
       " 'klue-ynat-bert-base-multilingual-cased/vocab.txt',\n",
       " 'klue-ynat-bert-base-multilingual-cased/added_tokens.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"klue-ynat-bert-base-multilingual-cased\"\n",
    "model.save_pretrained(model_path)\n",
    "tokenizer.save_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c387e85",
   "metadata": {},
   "source": [
    "Test Prediction\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed69d865",
   "metadata": {},
   "source": [
    "* 출력을 얻기위한 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ff7a99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    inputs = tokenizer(text, padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs[0].softmax(1)\n",
    "    return mapping[probs.argmax().item()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b1143",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7541db",
   "metadata": {},
   "source": [
    "### 뉴스 헤드라인을 입력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69166cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\"\n",
    "    내년 최저임금 9160원…\"자영업자 한계 상황…실업난 우려\" 中企 소상공인 반발\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8da45f",
   "metadata": {},
   "source": [
    "### 입력한 헤드라인의 Topic을 분류합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaa18e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경제\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
